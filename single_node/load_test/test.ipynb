{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://192.168.11.37:18091/metrics'\n",
    "\n",
    "response = requests.get(url)    # GET request to the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10000000):\n",
    "    time.sleep(1)    # Sleep for 1 second\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extracting the values of the metrics from the response\n",
    "        ## time_to_first_token_seconds\n",
    "        time_to_first_token_seconds_sum = re.search(r'vllm:time_to_first_token_seconds_sum{model_name=\"qwen2-7b\"} (\\d+\\.\\d+)', response.text)\n",
    "        time_to_first_token_seconds_sum_value = float(time_to_first_token_seconds_sum.group(1))\n",
    "        time_to_first_token_seconds_count = re.search(r'vllm:time_to_first_token_seconds_count{model_name=\"qwen2-7b\"} (\\d+)', response.text)\n",
    "        time_to_first_token_seconds_count_value = int(time_to_first_token_seconds_count.group(1))\n",
    "        time_to_first_token_seconds_avg = time_to_first_token_seconds_sum_value / time_to_first_token_seconds_count_value\n",
    "\n",
    "        ## request_prompt_tokens\n",
    "        request_prompt_tokens_sum = re.search(r'vllm:request_prompt_tokens_sum{model_name=\"qwen2-7b\"} (\\d+(?:\\.\\d+)?e[+-]?\\d+)', response.text)\n",
    "        request_prompt_tokens_sum_value = float(request_prompt_tokens_sum.group(1))\n",
    "        request_prompt_tokens_count = re.search(r'vllm:request_prompt_tokens_count{model_name=\"qwen2-7b\"} (\\d+)', response.text)\n",
    "        request_prompt_tokens_count_value = int(request_prompt_tokens_count.group(1))\n",
    "\n",
    "        request_prompt_tokens_avg = request_prompt_tokens_sum_value / request_prompt_tokens_count_value\n",
    "\n",
    "        ## request_generation_tokens\n",
    "        request_generation_tokens_sum = re.search(r'vllm:request_generation_tokens_sum{model_name=\"qwen2-7b\"} (\\d+)', response.text)\n",
    "        request_generation_tokens_sum_value = float(request_generation_tokens_sum.group(1))\n",
    "        request_generation_tokens_count = re.search(r'vllm:request_generation_tokens_count{model_name=\"qwen2-7b\"} (\\d+)', response.text)\n",
    "        request_generation_tokens_count_value = int(request_generation_tokens_count.group(1))\n",
    "        request_generation_tokens_avg = request_generation_tokens_sum_value / request_generation_tokens_count_value\n",
    "\n",
    "        ## request_total_tokens\n",
    "        e2e_request_latency_seconds_sum = re.search(r'vllm:e2e_request_latency_seconds_sum{model_name=\"qwen2-7b\"} (\\d+\\.\\d+)', response.text)   \n",
    "        e2e_request_latency_seconds_sum_value = float(e2e_request_latency_seconds_sum.group(1))\n",
    "        e2e_request_latency_seconds_count = re.search(r'vllm:e2e_request_latency_seconds_count{model_name=\"qwen2-7b\"} (\\d+)', response.text)\n",
    "        e2e_request_latency_seconds_count_value = int(e2e_request_latency_seconds_count.group(1))\n",
    "        e2e_request_latency_seconds_avg = e2e_request_latency_seconds_sum_value / e2e_request_latency_seconds_count_value\n",
    "\n",
    "        print(r'time_to_first_token_seconds_avg: %s, request_prompt_tokens_avg: %s, request_generation_tokens_avg: %s, e2e_request_latency_seconds_avg: %s' % (time_to_first_token_seconds_avg, request_prompt_tokens_avg, request_generation_tokens_avg, e2e_request_latency_seconds_avg))\n",
    "    else:\n",
    "        print('Error: Status code is not 200')\n",
    "        print('Trying again...')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
